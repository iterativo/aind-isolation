{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic Analysis\n",
    "\n",
    "### Approach\n",
    "\n",
    "In order to devise the *custom_score* functions logic, the following approach was used:\n",
    "\n",
    "1. Using self-observation and intuition when playing the game of isolation, I wrote down a set of strategies I noticed myself applying during the game to evaluate the state of my player in the game at any point in time. The following, are those strategies:\n",
    "\n",
    " - Comparing the amount of my own moves vs the opponent's: the more moves I had over my opponent's, the better.\n",
    " - My ability to block the opponent on their next move: since the goal of the game is to isolate the opponent, blocking their future moves seemed like a natural strategy.\n",
    " - My ability to take over the center of the board on my next move: this was also pointed out during the class instructional videos.\n",
    " - A relative measure of how close my player was to the center as compared to the opponent: in general, if my player was closer to the center than the opponent, the better it seemed, as it creates the notion of \"controling\" the center.\n",
    " - A simple count of the number of possible moves for my player: this is also captured in the out-of-the-box open-move strategy.\n",
    " \n",
    " There were other strategies I came up with during my brainstorming, but they were later discarded as irrelevant after further evaluation.\n",
    " <br/><br/>\n",
    "\n",
    "2. All of these strategies were later coded individually or in combination in the *custom_score* functions available in `game_agent.py`. When coded in combination, a similar approach to the one used when creating a Machine Learning model was utilized. I.e., a score function composed of the summation of the weighted features (strategies in this case) was applied. The general equation of the resulting function is:\n",
    "\n",
    " $$score = \\sum\\limits_{i=1}^{n}\\omega_i*x_i \\>\\>\\>\\> \\textit{, where n = number of strategies}$$\n",
    " <br/>\n",
    "3. Afterwards, their performance were evaluated by running `tournament.py` over sevaral runs. The evaluation included observing the following characteristics in the results:\n",
    " - noting the total *win rate* for each test player.\n",
    " - comparing all *AB_Custom\\** players to each opponent's result (paying attention to the opponent's strategy).\n",
    " - comparing all *AB_Custom\\** players results to the *AB_Improved* test player's for each opponent.\n",
    " <br/><br/>\n",
    "4. In an iterative fashion, each *custom_score* function was updated, by changing their param weights ($\\omega_i$) and adding or removing features to the equation ($x$) and further evaluated. This process allowed for the fine-tuning and optimization of the functions.\n",
    " <br/><br/>\n",
    "5. After several iterations, the final version of the *custom_score* functions was produced. As the last verification step, a *tournament* consisting of \"`NUM_MATCHES = 1000`\" was executed. The following screen shot summarizes the final results.\n",
    "\n",
    "<img src=\"files/img/1000_matches.png\"/>\n",
    "<p style=\"text-align: center;\">*Results of tournament final version of the custom_score functions over 1000 matches*</p>\n",
    "\n",
    "The results show both *AB_Custom* and *AB_Custom_2* perform slightly better than the *AB_Improved* test agent. Also, it is interesting to note that the strategy implemented by *AB_Custom* (`custom_score()`) tends to perform really well against the out-of-the-box \"center\" strategy (as shown by the performance against *MM_Center* and *AB_Center*); however, not as well, yet still better, when compared against the \"open-move\" and the \"improved\" strategies.\n",
    "\n",
    "This suggests that certain strategies work better than others under certain situations, depending on what the opponent's strategy is. In other words, there may not be a silver-bullet strategy that works well on all situations. A better, and more intuitive approach is to use an adaptive stragegy - one that can dynamically adapt to the opponent's behavior, much like a smart player would act.\n",
    "<br/>\n",
    "\n",
    "### Strategies utilized per custom_score function \n",
    "\n",
    "\n",
    "The following are the strategies utilized for each *custom_score* function:\n",
    "\n",
    "- **`custom_score()`**:\n",
    "  - `opponent_block_ability`\n",
    "  - `relative_mobility`\n",
    "- **`custom_score_2()`**:\n",
    "  - `center_ability`\n",
    "  - `opponent_block_ability`\n",
    "  - `own_mobility`\n",
    "  - `relative_center_domination`\n",
    "  - `relative_mobility`\n",
    "- **`custom_score_3()`**:\n",
    "  - `opponent_block_ability`\n",
    "  - `own_mobility`\n",
    "\n",
    "| Name | Strategy |\n",
    "|------|----------|\n",
    "| `center_ability` | Ability to capture board center |\n",
    "| `opponent_block_ability` | Ability to block the opponent |\n",
    "| `own_mobility` | Player # of next moves |\n",
    "| `relative_center_domination` | Player's distance to center vs opponent's |\n",
    "| `relative_mobility` | Player's moves vs opponent's |\n",
    "\n",
    "<p style=\"text-align: center;\">Strategy names as used in the *custom_score* functions</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
